[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I am Ayisha Beauge\nI am a student majoring in Statistics at the University of Florida.\nIâ€™m a passionate learner and aspiring data scientist with a growing interest in public health and youth safety. I completed a machine learning bootcamp as part of the FAU Summer Institute in Biostatistics and Data Science, where I explored how predictive models can inform real-world interventions.\nMy recent project focused on using machine learning techniquesâ€”including Random Forest, decision trees, Lasso regression, and logistic regression; to predict the likelihood of adolescents carrying a gun to school. By combining these models into a comparative ROC analysis, I aimed to better understand which variables and algorithms provide the most accurate insights.\nIâ€™m excited to continue applying data science to issues that matter and collaborating with others who share a vision for evidence-based solutions in public health.\nI am also dedicated to ensuring clarity and reproducibility in my work, using tools like Quarto and RMarkdown. This approach ensures that my research is trustworthy and easily followed by others.\n(If I had to describe myself in three emojis: ğŸ“ğŸ“šğŸˆ)"
  },
  {
    "objectID": "models/datasets.html",
    "href": "models/datasets.html",
    "title": "Data and Research Question",
    "section": "",
    "text": "The Youth Risk Behavior Survey (YRBS) is a national survey that monitors health-related behaviors among high school students, including weapon carrying and associated risk factors.\n\n\n\nSource: Centers for Disease Control and Prevention (CDC)\nYear: 2023\nTarget Population: High school students\nSample Size: Approximately 19,000 students nationwide\n\n\n\n\nHow do logistic regression, lasso, k-nearest neighbors, and tree-based models compare in predicting school-based weapon carrying among adolescents based on risk and protective factors?\n\n\n\nThe dataset includes information on various health-related behaviors:\n\nOutcome\n\nWeapon Carrying (Carried a weapon on school property)\n\nPredictors\n\nTraumatic experiences\nSchool Safety Perceptions\nBullying Experiences\nFamily Support\nSocial Media Use\nPeer Relationships\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dissertationData)\nlibrary(here)\ndata(clean_yrbs_2023)\n# Add your data preprocessing code here\n\n\n\n\nWe will do it in classâ€¦\n\n\n\n\n# This is an example of how to create a dataset for a model.\n# You can use this as a template to create your own dataset.\n\n\nanalysis_data &lt;- clean_yrbs_2023 %&gt;%\n    select(\n        WeaponCarryingSchool, AttackedInNeighborhood, Bullying,\n        SexualAbuseByOlderPerson, ParentalPhysicalAbuse, ParentSubstanceUse,\n        ParentIncarceration, SchoolConnectedness, ParentalMonitoring,\n        UnfairDisciplineAtSchool, Homelessness\n    ) |&gt;\n    filter(!is.na(WeaponCarryingSchool)) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ as.numeric(.x) - 1\n    )) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ factor(.x)\n    ))\n\n\n\n\n\n\n\n\nanalysis_folds &lt;- vfold_cv(analysis_train,\n    v = 5\n)\nanalysis_folds"
  },
  {
    "objectID": "models/datasets.html#youth-risk-behavior-survey-2023",
    "href": "models/datasets.html#youth-risk-behavior-survey-2023",
    "title": "Data and Research Question",
    "section": "",
    "text": "The Youth Risk Behavior Survey (YRBS) is a national survey that monitors health-related behaviors among high school students, including weapon carrying and associated risk factors.\n\n\n\nSource: Centers for Disease Control and Prevention (CDC)\nYear: 2023\nTarget Population: High school students\nSample Size: Approximately 19,000 students nationwide\n\n\n\n\nHow do logistic regression, lasso, k-nearest neighbors, and tree-based models compare in predicting school-based weapon carrying among adolescents based on risk and protective factors?\n\n\n\nThe dataset includes information on various health-related behaviors:\n\nOutcome\n\nWeapon Carrying (Carried a weapon on school property)\n\nPredictors\n\nTraumatic experiences\nSchool Safety Perceptions\nBullying Experiences\nFamily Support\nSocial Media Use\nPeer Relationships\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dissertationData)\nlibrary(here)\ndata(clean_yrbs_2023)\n# Add your data preprocessing code here\n\n\n\n\nWe will do it in classâ€¦\n\n\n\n\n# This is an example of how to create a dataset for a model.\n# You can use this as a template to create your own dataset.\n\n\nanalysis_data &lt;- clean_yrbs_2023 %&gt;%\n    select(\n        WeaponCarryingSchool, AttackedInNeighborhood, Bullying,\n        SexualAbuseByOlderPerson, ParentalPhysicalAbuse, ParentSubstanceUse,\n        ParentIncarceration, SchoolConnectedness, ParentalMonitoring,\n        UnfairDisciplineAtSchool, Homelessness\n    ) |&gt;\n    filter(!is.na(WeaponCarryingSchool)) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ as.numeric(.x) - 1\n    )) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ factor(.x)\n    ))\n\n\n\n\n\n\n\n\nanalysis_folds &lt;- vfold_cv(analysis_train,\n    v = 5\n)\nanalysis_folds"
  },
  {
    "objectID": "models/lasso.html",
    "href": "models/lasso.html",
    "title": "Lasso Regression",
    "section": "",
    "text": "Lasso regression is a statistical model that combines linear/logistic regression with L1 regularization to perform both variable selection and regularization. The term â€œLassoâ€ stands for â€œLeast Absolute Shrinkage and Selection Operator.â€ This method is particularly useful when dealing with datasets that have many predictors, as it helps to: - Reduce overfitting by penalizing large coefficients - Perform automatic feature selection by shrinking some coefficients to exactly zero - Handle multicollinearity by selecting only one variable from a group of highly correlated predictors\nIn this analysis, weâ€™ll use Lasso regression to predict weapon carrying behavior in schools, demonstrating how this method can help identify the most important predictors while maintaining model interpretability."
  },
  {
    "objectID": "models/lasso.html#setting-up-the-environment",
    "href": "models/lasso.html#setting-up-the-environment",
    "title": "Lasso Regression",
    "section": "Setting Up the Environment",
    "text": "Setting Up the Environment\nFirst, we need to load the necessary packages for our analysis. Weâ€™ll use tidymodels for modeling, tidyverse for data manipulation, and here for consistent file paths.\n\nlibrary(here)\nlibrary(tidymodels)\nlibrary(tidyverse)"
  },
  {
    "objectID": "models/lasso.html#loading-the-data",
    "href": "models/lasso.html#loading-the-data",
    "title": "Lasso Regression",
    "section": "Loading the Data",
    "text": "Loading the Data\nWeâ€™ll work with pre-processed data sets that have been split into training and test sets, along with cross-validation folds. These files are stored in the processed_data directory.\n\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test &lt;- readRDS(here(\"models\",\"data\", \"analysis_test.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))"
  },
  {
    "objectID": "models/lasso.html#data-preprocessing",
    "href": "models/lasso.html#data-preprocessing",
    "title": "Lasso Regression",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nBefore fitting our model, we need to preprocess the data. Weâ€™ll create a recipe that: - Imputes missing values in categorical variables using the mode - Imputes missing values in numeric variables using the mean - Removes predictors with zero variance - Removes highly correlated predictors (correlation threshold = 0.7) - Creates dummy variables for categorical predictors\n\nweapon_carry_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_zv(all_predictors()) |&gt; \n  step_corr(all_numeric_predictors(), threshold = 0.7) %&gt;% \n  step_dummy(all_nominal_predictors())\n\nweapon_carry_recipe\n\n\n\n\nâ”€â”€ Recipe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n\n\n\nâ”€â”€ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\nâ”€â”€ Operations \n\n\nâ€¢ Mode imputation for: all_nominal_predictors()\n\n\nâ€¢ Mean imputation for: all_numeric_predictors()\n\n\nâ€¢ Zero variance filter on: all_predictors()\n\n\nâ€¢ Correlation filter on: all_numeric_predictors()\n\n\nâ€¢ Dummy variables from: all_nominal_predictors()\n\n\nLetâ€™s apply our recipe to transform the data according to these preprocessing steps.\n\nweapon_carry_recipe %&gt;% \n  prep() %&gt;% \n  bake(new_data = analysis_data) \n\n# A tibble: 19,595 Ã— 11\n   WeaponCarryingSchool AttackedInNeighborhood_X1 Bullying_X1\n   &lt;fct&gt;                                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 0                                            0           0\n 2 0                                            0           1\n 3 0                                            0           0\n 4 0                                            0           0\n 5 0                                            0           0\n 6 0                                            1           0\n 7 0                                            0           0\n 8 0                                            0           0\n 9 0                                            0           0\n10 0                                            0           0\n# â„¹ 19,585 more rows\n# â„¹ 8 more variables: SexualAbuseByOlderPerson_X1 &lt;dbl&gt;,\n#   ParentalPhysicalAbuse_X1 &lt;dbl&gt;, ParentSubstanceUse_X1 &lt;dbl&gt;,\n#   ParentIncarceration_X1 &lt;dbl&gt;, SchoolConnectedness_X1 &lt;dbl&gt;,\n#   ParentalMonitoring_X1 &lt;dbl&gt;, UnfairDisciplineAtSchool_X1 &lt;dbl&gt;,\n#   Homelessness_X1 &lt;dbl&gt;"
  },
  {
    "objectID": "models/lasso.html#model-specification",
    "href": "models/lasso.html#model-specification",
    "title": "Lasso Regression",
    "section": "Model Specification",
    "text": "Model Specification\nWeâ€™ll use a logistic regression model with Lasso regularization. The Lasso (Least Absolute Shrinkage and Selection Operator) helps with feature selection by penalizing the absolute size of coefficients. We set mixture = 1 to specify a pure Lasso model, and weâ€™ll tune the penalty parameter to find the optimal level of regularization.\n\nweapon_carry_spec &lt;-\n  logistic_reg(penalty = tune(), \n               mixture = 1) |&gt; \n  set_engine('glmnet')\n\nweapon_carry_spec\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#creating-the-workflow",
    "href": "models/lasso.html#creating-the-workflow",
    "title": "Lasso Regression",
    "section": "Creating the Workflow",
    "text": "Creating the Workflow\nWeâ€™ll combine our recipe and model specification into a single workflow. This ensures that all preprocessing steps are properly applied during both training and prediction.\n\nweapon_carry_workflow &lt;-\n  workflow() |&gt;\n  add_recipe(weapon_carry_recipe) |&gt;\n  add_model(weapon_carry_spec)\n\nweapon_carry_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n5 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_zv()\nâ€¢ step_corr()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#model-tuning",
    "href": "models/lasso.html#model-tuning",
    "title": "Lasso Regression",
    "section": "Model Tuning",
    "text": "Model Tuning\nTo find the optimal penalty value, weâ€™ll create a grid of potential values to test. Weâ€™ll use 50 different penalty values, evenly spaced on a logarithmic scale.\n\nlambda_grid &lt;- grid_regular(penalty(), levels = 50)\nlambda_grid\n\n# A tibble: 50 Ã— 1\n    penalty\n      &lt;dbl&gt;\n 1 1   e-10\n 2 1.60e-10\n 3 2.56e-10\n 4 4.09e-10\n 5 6.55e-10\n 6 1.05e- 9\n 7 1.68e- 9\n 8 2.68e- 9\n 9 4.29e- 9\n10 6.87e- 9\n# â„¹ 40 more rows\n\n\nNow, weâ€™ll perform cross-validation to find the best penalty value. This process is time-consuming, so weâ€™ll save the results for future use.\n\nset.seed(2023)\n\nlasso_tune &lt;- \n  tune_grid(\n  object = weapon_carry_workflow, \n  resamples = analysis_folds,\n  grid = lambda_grid, \n  control = control_resamples(event_level = \"second\")\n)\n\nLetâ€™s examine the performance metrics for different penalty values.\n\nlasso_tune %&gt;% \n  collect_metrics()\n\n# A tibble: 150 Ã— 7\n    penalty .metric     .estimator  mean     n std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 1   e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model01\n 2 1   e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model01\n 3 1   e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model01\n 4 1.60e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model02\n 5 1.60e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model02\n 6 1.60e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model02\n 7 2.56e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model03\n 8 2.56e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model03\n 9 2.56e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model03\n10 4.09e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model04\n# â„¹ 140 more rows\n\n\nWe can visualize how the modelâ€™s performance changes with different penalty values.\n\nautoplot(lasso_tune)"
  },
  {
    "objectID": "models/lasso.html#selecting-the-best-model",
    "href": "models/lasso.html#selecting-the-best-model",
    "title": "Lasso Regression",
    "section": "Selecting the Best Model",
    "text": "Selecting the Best Model\nWeâ€™ll select the best model based on the ROC AUC metric, which measures the modelâ€™s ability to distinguish between classes.\n\nbest &lt;- lasso_tune |&gt; \n  select_best(metric =\"roc_auc\")\n\nbest\n\n# A tibble: 1 Ã— 2\n   penalty .config              \n     &lt;dbl&gt; &lt;chr&gt;                \n1 0.000339 Preprocessor1_Model33\n\n\nNow weâ€™ll create our final workflow with the best penalty value.\n\nfinal_wf &lt;- finalize_workflow(weapon_carry_workflow, best)\n\nfinal_wf\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n5 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_zv()\nâ€¢ step_corr()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.000339322177189533\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#fitting-the-final-model",
    "href": "models/lasso.html#fitting-the-final-model",
    "title": "Lasso Regression",
    "section": "Fitting the Final Model",
    "text": "Fitting the Final Model\nWeâ€™ll fit our final model on the training data. This process is also time-consuming, so weâ€™ll save the results.\n\nweapon_fit &lt;- \n  fit(final_wf, data = analysis_train)\n\nweapon_fit"
  },
  {
    "objectID": "models/lasso.html#model-evaluation",
    "href": "models/lasso.html#model-evaluation",
    "title": "Lasso Regression",
    "section": "Model Evaluation",
    "text": "Model Evaluation\nLetâ€™s examine the modelâ€™s predictions on the training data.\n\nweapon_pred &lt;- \n  augment(weapon_fit, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0368   0.963\n 2 0                    0            0.0410   0.959\n 3 0                    0            0.0253   0.975\n 4 0                    0            0.0325   0.968\n 5 0                    0            0.125    0.875\n 6 0                    0            0.0368   0.963\n 7 0                    0            0.0208   0.979\n 8 0                    0            0.0208   0.979\n 9 0                    0            0.0458   0.954\n10 0                    0            0.0529   0.947\n# â„¹ 14,686 more rows\n\n\nWe can visualize the modelâ€™s performance using an ROC curve.\n\nroc_plot_training &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |&gt; \n  autoplot()\n\nroc_plot_training \n\n\n\n\n\n\n\n\nLetâ€™s look at the model coefficients to understand which predictors are most important.\n\nweapon_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  tidy()\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n\n# A tibble: 11 Ã— 3\n   term                        estimate  penalty\n   &lt;chr&gt;                          &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                  -3.29   0.000339\n 2 AttackedInNeighborhood_X1     0.739  0.000339\n 3 Bullying_X1                   0.472  0.000339\n 4 SexualAbuseByOlderPerson_X1   0.455  0.000339\n 5 ParentalPhysicalAbuse_X1      0.708  0.000339\n 6 ParentSubstanceUse_X1        -0.132  0.000339\n 7 ParentIncarceration_X1        0.0271 0.000339\n 8 SchoolConnectedness_X1       -0.226  0.000339\n 9 ParentalMonitoring_X1         0.584  0.000339\n10 UnfairDisciplineAtSchool_X1  -0.229  0.000339\n11 Homelessness_X1               1.17   0.000339"
  },
  {
    "objectID": "models/lasso.html#cross-validation-results",
    "href": "models/lasso.html#cross-validation-results",
    "title": "Lasso Regression",
    "section": "Cross-Validation Results",
    "text": "Cross-Validation Results\nWeâ€™ll fit the model on each cross-validation fold to get a more robust estimate of its performance.\n\nweapon_fit_resamples &lt;- \n  fit_resamples(final_wf, resamples = analysis_folds)\n\nweapon_fit_resamples\n\nLetâ€™s examine the cross-validation metrics.\n\ncollect_metrics(weapon_fit_resamples)\n\n# A tibble: 3 Ã— 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.957      5 0.00158 Preprocessor1_Model1\n2 brier_class binary     0.0399     5 0.00128 Preprocessor1_Model1\n3 roc_auc     binary     0.688      5 0.00737 Preprocessor1_Model1"
  },
  {
    "objectID": "models/lasso.html#variable-importance",
    "href": "models/lasso.html#variable-importance",
    "title": "Lasso Regression",
    "section": "Variable Importance",
    "text": "Variable Importance\nFinally, letâ€™s create a variable importance plot to identify the most influential predictors in our model.\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nweapon_fit |&gt; \n  extract_fit_engine() |&gt; \n  vip()"
  },
  {
    "objectID": "models/lasso.html#results-and-interpretation",
    "href": "models/lasso.html#results-and-interpretation",
    "title": "Lasso Regression",
    "section": "Results and Interpretation",
    "text": "Results and Interpretation\n[Add your interpretation of the results here]"
  },
  {
    "objectID": "models/logistic.html",
    "href": "models/logistic.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Logistic regression is a statistical model thatâ€¦\n\nModel Overview\nLogistic regression is used when the dependent variable is binary (0/1, Yes/No, True/False). The model estimates the probability of the dependent variable being 1 given the independent variables.\n\n\nImplementation\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(dissertationData)\nlibrary(here)\n\n# Load and prepare the YRBS 2023 dataset\n\n\n\nLoad the data\n\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test &lt;- readRDS(here(\"models\", \"data\", \"analysis_test.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n\n\n\nRecipe\n\nweapon_carry_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_data) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_zv(all_predictors()) |&gt; \n  step_corr(all_numeric_predictors(), threshold = 0.7) \n\nweapon_carry_recipe\n\n\n\n\nâ”€â”€ Recipe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n\n\n\nâ”€â”€ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\nâ”€â”€ Operations \n\n\nâ€¢ Mode imputation for: all_nominal_predictors()\n\n\nâ€¢ Mean imputation for: all_numeric_predictors()\n\n\nâ€¢ Zero variance filter on: all_predictors()\n\n\nâ€¢ Correlation filter on: all_numeric_predictors()\n\n\n\n\nBake\n\nrec &lt;- weapon_carry_recipe %&gt;% \n  prep() %&gt;% \n  bake(new_data = analysis_data) %&gt;% glimpse()\n\nRows: 19,595\nColumns: 11\n$ AttackedInNeighborhood   &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, â€¦\n$ Bullying                 &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ SexualAbuseByOlderPerson &lt;fct&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, â€¦\n$ ParentalPhysicalAbuse    &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ ParentSubstanceUse       &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, â€¦\n$ ParentIncarceration      &lt;fct&gt; 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n$ SchoolConnectedness      &lt;fct&gt; 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, â€¦\n$ ParentalMonitoring       &lt;fct&gt; 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, â€¦\n$ UnfairDisciplineAtSchool &lt;fct&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n$ Homelessness             &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ WeaponCarryingSchool     &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n\n\n\n\nModel Specification\n\nweapon_carry_spec &lt;- \n  logistic_reg() %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"glm\") \n\nweapon_carry_spec\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nWorkflow\n\nweapon_carry_workflow &lt;- workflow() %&gt;%\n  add_recipe(weapon_carry_recipe) %&gt;%\n  add_model(weapon_carry_spec)\n\n\nweapon_carry_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n4 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_zv()\nâ€¢ step_corr()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\nmod_1 &lt;- \n  fit(weapon_carry_workflow, data = analysis_train) \n\nmod_1\n\nâ•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n4 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_zv()\nâ€¢ step_corr()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n              (Intercept)    AttackedInNeighborhood1  \n                 -3.29938                    0.74950  \n                Bullying1  SexualAbuseByOlderPerson1  \n                  0.48405                    0.46540  \n   ParentalPhysicalAbuse1        ParentSubstanceUse1  \n                  0.71713                   -0.15917  \n     ParentIncarceration1       SchoolConnectedness1  \n                  0.07048                   -0.25542  \n      ParentalMonitoring1  UnfairDisciplineAtSchool1  \n                  0.59860                   -0.24268  \n            Homelessness1  \n                  1.18053  \n\nDegrees of Freedom: 14695 Total (i.e. Null);  14685 Residual\nNull Deviance:      5238 \nResidual Deviance: 4872     AIC: 4894\n\n\n\ntidy_model &lt;- \n  mod_1 |&gt;\n  tidy(exponentiate = TRUE,\n       conf.int = TRUE, \n       conf.level = .95) |&gt;\n  mutate(p.value = scales::pvalue(p.value))\n\ntidy_model\n\n# A tibble: 11 Ã— 7\n   term                  estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)             0.0369    0.166    -19.9   &lt;0.001    0.0266    0.0508\n 2 AttackedInNeighborhoâ€¦   2.12      0.0954     7.85  &lt;0.001    1.75      2.55  \n 3 Bullying1               1.62      0.0919     5.27  &lt;0.001    1.35      1.94  \n 4 SexualAbuseByOlderPeâ€¦   1.59      0.133      3.51  &lt;0.001    1.22      2.06  \n 5 ParentalPhysicalAbusâ€¦   2.05      0.179      4.01  &lt;0.001    1.43      2.89  \n 6 ParentSubstanceUse1     0.853     0.111     -1.44  0.151     0.688     1.06  \n 7 ParentIncarceration1    1.07      0.126      0.560 0.575     0.841     1.38  \n 8 SchoolConnectedness1    0.775     0.0970    -2.63  0.008     0.639     0.935 \n 9 ParentalMonitoring1     1.82      0.114      5.26  &lt;0.001    1.45      2.27  \n10 UnfairDisciplineAtScâ€¦   0.785     0.114     -2.13  0.033     0.629     0.984 \n11 Homelessness1           3.26      0.155      7.61  &lt;0.001    2.39      4.39  \n\n\n\n\nModel Evaluation\n\nweapon_pred &lt;- \n  augment(mod_1, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0360   0.964\n 2 0                    0            0.0412   0.959\n 3 0                    0            0.0241   0.976\n 4 0                    0            0.0317   0.968\n 5 0                    0            0.128    0.872\n 6 0                    0            0.0360   0.964\n 7 0                    0            0.0201   0.980\n 8 0                    0            0.0201   0.980\n 9 0                    0            0.0471   0.953\n10 0                    0            0.0531   0.947\n# â„¹ 14,686 more rows\n\n\n\nroc_plot_training &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |&gt; \n  autoplot()\n\nroc_plot_training \n\n\n\n\n\n\nVisualizations\n\ntidy_model |&gt; \n  filter(term != \"(Intercept)\") |&gt; \n  ggplot(aes(x = estimate, y = reorder(term, estimate))) +\n  geom_point(size = 3) +\n  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"red\") +\n  scale_x_log10() +\n  labs(\n    x = \"Odds Ratio (log scale)\",\n    y = \"Predictors\",\n    title = \"Forest Plot of Logistic Regression Coefficients\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 10),\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\nResults and Interpretation\n\n\nKey Takeaways"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Notebook ğŸ‘€",
    "section": "",
    "text": "This website will be our Machine Learning course, where we explore various statistical and machine learning models using the Youth Risk Behavior Survey (YRBS) 2023 dataset. Through this course, I learned to implement and understand different modeling techniques using the tidymodels framework in R.\n\nWhat Youâ€™ll Find Here\n\nAbout Me: A little bit about me and my research interests.\nThe Dataset: Information about my primary dataset and the research question I am trying to answer.\nModel Implementations: Hands-on examples of different models to answer the question:\n\nLogistic Regression\nLasso Regression\nDecision Trees\nRandom Forest\nK-Nearest Neighbors (KNN)"
  },
  {
    "objectID": "models/trees.html",
    "href": "models/trees.html",
    "title": "Classification Tree",
    "section": "",
    "text": "##Library\n\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n\n\ncarry_weapon_recipe_tree &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) \n  \ncarry_weapon_recipe_tree\n\n\n\n\nâ”€â”€ Recipe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n\n\n\nâ”€â”€ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\nâ”€â”€ Operations \n\n\nâ€¢ Mode imputation for: all_nominal_predictors()\n\n\nâ€¢ Mean imputation for: all_numeric_predictors()\n\n\n\ncarry_weapon_spec_tree &lt;- \n  decision_tree(\n   cost_complexity = tune(),\n   tree_depth = tune(),\n   min_n = tune()) |&gt;  \n  set_engine(\"rpart\") |&gt; \n  set_mode(\"classification\")\n\ncarry_weapon_spec_tree \n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n  min_n = tune()\n\nComputational engine: rpart \n\n\n\ncarry_weapon_workflow_tree &lt;-\nworkflow () |&gt;\n  add_recipe(carry_weapon_recipe_tree) |&gt;\n  add_model(carry_weapon_spec_tree)\ncarry_weapon_workflow_tree\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: decision_tree()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n2 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n  min_n = tune()\n\nComputational engine: rpart \n\n\n##tree tunifn\n\ntree_grid &lt;- \n  grid_regular(cost_complexity(),\n               tree_depth(c(2, 5)),\n               min_n(), \n               levels = 2)\ntree_grid\n\n# A tibble: 8 Ã— 3\n  cost_complexity tree_depth min_n\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;\n1    0.0000000001          2     2\n2    0.1                   2     2\n3    0.0000000001          5     2\n4    0.1                   5     2\n5    0.0000000001          2    40\n6    0.1                   2    40\n7    0.0000000001          5    40\n8    0.1                   5    40\n\n\n\ncart_tune &lt;- \n  carry_weapon_workflow_tree |&gt;\n  tune_grid(resamples = analysis_folds,\n            grid = tree_grid, \n            metrics = metric_set(roc_auc),\n            control = control_grid(save_pred = TRUE)\n  )\n\ncart_tune\n\nsaveRDS(cart_tune, here(\"model_outputs\", \"tree_tune.rds\"))\n\n\nbestPlot_cart &lt;- \n  autoplot(cart_tune)\n\nbestPlot_cart\n\n\n\n\n\n\n\n\n\nbest_cart &lt;- select_best(\n  cart_tune, \n  metric = \"roc_auc\")\n\nbest_cart\n\n# A tibble: 1 Ã— 4\n  cost_complexity tree_depth min_n .config             \n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;               \n1    0.0000000001          5     2 Preprocessor1_Model3\n\n\n\ncart_final_wf &lt;- finalize_workflow(carry_weapon_workflow_tree, best_cart)\ncart_final_wf\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: decision_tree()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n2 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 5\n  min_n = 2\n\nComputational engine: rpart \n\n\n\ncart_fit &lt;- fit(\n  cart_final_wf, \n  analysis_train)\n\ncart_fit\n\nsaveRDS(cart_fit, here(\"model_outputs\", \"tree_fit.rds\"))\n\n\ntree_pred &lt;- \n  augment(cart_fit, analysis_train) |&gt;\n  \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\ntree_pred\n\n# A tibble: 14,696 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0396   0.960\n 2 0                    0            0.0396   0.960\n 3 0                    0            0.0396   0.960\n 4 0                    0            0.0396   0.960\n 5 0                    0            0.0396   0.960\n 6 0                    0            0.0396   0.960\n 7 0                    0            0.0396   0.960\n 8 0                    0            0.0396   0.960\n 9 0                    0            0.0396   0.960\n10 0                    0            0.0396   0.960\n# â„¹ 14,686 more rows\n\n\n\nroc_tree &lt;- tree_pred |&gt;\n  roc_curve(truth = WeaponCarryingSchool, .pred_1,\n            event_level = \"second\") |&gt;\nautoplot()\n\nsaveRDS(roc_tree, here(\"models\", \"roc_graphs\",\"tree.rds\"))\n\n\n#second part\ntree_pred |&gt; \n  roc_auc(truth = WeaponCarryingSchool, \n           .pred_1, \n           event_level = \"second\")\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.544\n\nsaveRDS(roc_tree, here(\"models\", \"roc_graphs\", \"tree.rds\"))\n\n\nfit_resamples(cart_final_wf, resamples = analysis_folds) |&gt; \n  collect_metrics()\n\n# A tibble: 3 Ã— 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.955      5 0.00141 Preprocessor1_Model1\n2 brier_class binary     0.0412     5 0.00135 Preprocessor1_Model1\n3 roc_auc     binary     0.592      5 0.0226  Preprocessor1_Model1\n\n\n\nlibrary(rpart.plot)\n\nWarning: package 'rpart.plot' was built under R version 4.3.3\n\ncart_fit |&gt; \n  extract_fit_engine() |&gt; \nrpart.plot::rpart.plot(roundint=FALSE)"
  },
  {
    "objectID": "models/roc_graphs.html",
    "href": "models/roc_graphs.html",
    "title": "roc_Graphs",
    "section": "",
    "text": "roc_logistic &lt;- readRDS(\"roc_graphs/logistics.rds\")\nroc_lasso &lt;- readRDS(\"roc_graphs/lasso.rds\")\nroc_random &lt;- readRDS(\"roc_graphs/random_forest.rds\")\n\n\nlogistic &lt;- roc_logistic$data |&gt;\n  mutate(model = \"logistic\")\n\nlasso &lt;- roc_lasso$data |&gt;\n  mutate(model = \"lasso\")\n\nrandom &lt;- roc_random$data |&gt;\n  mutate(model = \"random\")\n\ncompare_roc &lt;-\n  bind_rows(\n    logistic, lasso, random\n    \n  ) |&gt;\n  ggplot(\n    aes(x = 1 - specificity, y = sensitivity, col = model)\n  ) +\n  geom_path(lwd = 0.5, alpha = 1) +\n   geom_abline(lty = 2) +\n  coord_equal()\ncompare_roc"
  },
  {
    "objectID": "models/Random_forest.html",
    "href": "models/Random_forest.html",
    "title": "Random Forest",
    "section": "",
    "text": "Library\n###Loading the data\n\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n\n###SPLIT THE DATA\n\nset.seed(2023)\n\nWeapon_split &lt;- initial_split(analysis_data, \n                               strata = WeaponCarryingSchool)\n\nweapon_train &lt;- training(Weapon_split)\nweapon_test &lt;- testing(Weapon_split)\n\nWeapon_split\n\n&lt;Training/Testing/Total&gt;\n&lt;14696/4899/19595&gt;\n\n\n###Lets check our work\n\nweapon_train |&gt; \n  tabyl(WeaponCarryingSchool)  |&gt; \n  adorn_pct_formatting(0) |&gt; \n  adorn_totals()\n\n WeaponCarryingSchool     n percent\n                    0 14042     96%\n                    1   654      4%\n                Total 14696       -\n\n\n\nweapon_test |&gt;  \n  tabyl(WeaponCarryingSchool)  |&gt; \n  adorn_pct_formatting(0) |&gt; \n  adorn_totals()\n\n WeaponCarryingSchool    n percent\n                    0 4705     96%\n                    1  194      4%\n                Total 4899       -\n\n\n\nset.seed(2023)\n\ncv_weapon &lt;- rsample::vfold_cv(weapon_train, \n                                v= 5,\n                                strata = WeaponCarryingSchool)\ncv_weapon\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 Ã— 2\n  splits               id   \n  &lt;list&gt;               &lt;chr&gt;\n1 &lt;split [11756/2940]&gt; Fold1\n2 &lt;split [11757/2939]&gt; Fold2\n3 &lt;split [11757/2939]&gt; Fold3\n4 &lt;split [11757/2939]&gt; Fold4\n5 &lt;split [11757/2939]&gt; Fold5\n\n\n\nweapon_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = weapon_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt; \n  step_dummy(all_nominal_predictors())\n\n\nweapon_spec &lt;- \n  rand_forest(\n    # the number of predictors to sample at each split\n    mtry = tune(), \n    # the number of observations needed to keep splitting nodes\n    min_n = tune(),\n    trees = 100) |&gt;  \n  set_mode(\"classification\") |&gt;  \n  set_engine(\"ranger\", \n             # This is essential for vip()\n             importance = \"permutation\") \n\nweapon_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\nweapon_workflow &lt;- \n  workflow() |&gt; \n  add_recipe(weapon_recipe) |&gt;  \n  add_model(weapon_spec) \n\nweapon_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\ndoParallel::registerDoParallel()\n  \nset.seed(46257)\n  \nweapon_tune &lt;-\n  tune_grid(\n    weapon_workflow,\n    resamples = cv_weapon,\n# grid = 11 says to choose 11 parameter sets automatically \n    grid = 11)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nWarning: ! tune detected a parallel backend registered with foreach but no backend\n  registered with future.\nâ„¹ Support for parallel processing with foreach was soft-deprecated in tune\n  1.2.1.\nâ„¹ See ?parallelism (`?tune::parallelism()`) to learn more.\n\ndoParallel::stopImplicitCluster() \nweapon_tune\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 Ã— 4\n  splits               id    .metrics          .notes          \n  &lt;list&gt;               &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [11756/2940]&gt; Fold1 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n2 &lt;split [11757/2939]&gt; Fold2 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n3 &lt;split [11757/2939]&gt; Fold3 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n4 &lt;split [11757/2939]&gt; Fold4 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n5 &lt;split [11757/2939]&gt; Fold5 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n\n\n\ncollect_metrics(weapon_tune)\n\n# A tibble: 33 Ã— 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    17 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0417     5 0.00137 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.673      5 0.00677 Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0417     5 0.00137 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.673      5 0.00931 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0417     5 0.00128 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.672      5 0.00663 Preprocessor1_Model03\n10     3    21 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model04\n# â„¹ 23 more rows\n\n\n\nautoplot(weapon_tune) \n\n\n\n\n\nbest_weapon &lt;- select_best(weapon_tune, metric = \"roc_auc\")\nbest_weapon\n\n# A tibble: 1 Ã— 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    32 Preprocessor1_Model02\n\n\n\nweapon_final_wf &lt;- finalize_workflow(weapon_workflow, best_weapon)\nweapon_final_wf\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 32\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\nweapon_fit &lt;- fit(weapon_final_wf, weapon_train)\nweapon_fit\n\nâ•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L,      x), num.trees = ~100, min.node.size = min_rows(~32L, x),      importance = ~\"permutation\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  100 \nSample size:                      14696 \nNumber of independent variables:  10 \nMtry:                             1 \nTarget node size:                 32 \nVariable importance mode:         permutation \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.04166282 \n\n\n\nweapon_pred &lt;- \n  augment(weapon_fit, weapon_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0489   0.951\n 2 0                    0            0.0430   0.957\n 3 0                    0            0.0351   0.965\n 4 0                    0            0.0412   0.959\n 5 0                    0            0.0327   0.967\n 6 0                    0            0.0880   0.912\n 7 0                    0            0.0489   0.951\n 8 0                    0            0.0324   0.968\n 9 0                    0            0.0488   0.951\n10 0                    0            0.0324   0.968\n# â„¹ 14,686 more rows\n\n\n\nweapon_roc_plot &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_1, \n           event_level = \"second\") |&gt; \n  autoplot()\n\nweapon_roc_plot\n\nsaveRDS(weapon_roc_plot, here(\"models\", \"roc_graphs\", \"random_forest.rds\"))\n\n\nweapon_pred |&gt; \n  roc_auc(truth = WeaponCarryingSchool, \n           .pred_1, \n           event_level = \"second\")\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.683"
  },
  {
    "objectID": "models/all_together.html",
    "href": "models/all_together.html",
    "title": "all_together",
    "section": "",
    "text": "#ALL the ROCS togther\n\nroc_logistic &lt;- readRDS(\"roc_graphs/logistics.rds\")\n\nroc_lasso &lt;- readRDS(\"roc_graphs/lasso.rds\")\n\nroc_random &lt;- readRDS(\"roc_graphs/random_forest.rds\")\nlogistic &lt;- roc_logistic$data |&gt;\n  mutate(model = \"logistic\")\n\nlasso &lt;- roc_lasso$data |&gt;\n  mutate(model = \"lasso\")\n\nrandom &lt;- roc_random$data |&gt;\n  mutate(model = \"random\")\n\ncompare_roc &lt;-\n  bind_rows(\n    logistic, lasso, random\n    \n  ) |&gt;\n  ggplot(\n    aes(x = 1 - specificity, y = sensitivity, col = model)\n  ) +\n  geom_path(lwd = 0.5, alpha = 1) +\n   geom_abline(lty = 2) +\n  coord_equal()\ncompare_roc"
  },
  {
    "objectID": "docs/models/random-forest.html",
    "href": "docs/models/random-forest.html",
    "title": "Random Forest",
    "section": "",
    "text": "Library\n###Loading the data\n\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n\n###SPLIT THE DATA\n\nset.seed(2023)\n\nWeapon_split &lt;- initial_split(analysis_data, \n                               strata = WeaponCarryingSchool)\n\nweapon_train &lt;- training(Weapon_split)\nweapon_test &lt;- testing(Weapon_split)\n\nWeapon_split\n\n&lt;Training/Testing/Total&gt;\n&lt;14696/4899/19595&gt;\n\n\n###Lets check our work\n\nweapon_train |&gt; \n  tabyl(WeaponCarryingSchool)  |&gt; \n  adorn_pct_formatting(0) |&gt; \n  adorn_totals()\n\n WeaponCarryingSchool     n percent\n                    0 14042     96%\n                    1   654      4%\n                Total 14696       -\n\n\n\nweapon_test |&gt;  \n  tabyl(WeaponCarryingSchool)  |&gt; \n  adorn_pct_formatting(0) |&gt; \n  adorn_totals()\n\n WeaponCarryingSchool    n percent\n                    0 4705     96%\n                    1  194      4%\n                Total 4899       -\n\n\n\nset.seed(2023)\n\ncv_weapon &lt;- rsample::vfold_cv(weapon_train, \n                                v= 5,\n                                strata = WeaponCarryingSchool)\ncv_weapon\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 Ã— 2\n  splits               id   \n  &lt;list&gt;               &lt;chr&gt;\n1 &lt;split [11756/2940]&gt; Fold1\n2 &lt;split [11757/2939]&gt; Fold2\n3 &lt;split [11757/2939]&gt; Fold3\n4 &lt;split [11757/2939]&gt; Fold4\n5 &lt;split [11757/2939]&gt; Fold5\n\n\n\nweapon_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = weapon_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt; \n  step_dummy(all_nominal_predictors())\n\n\nweapon_spec &lt;- \n  rand_forest(\n    # the number of predictors to sample at each split\n    mtry = tune(), \n    # the number of observations needed to keep splitting nodes\n    min_n = tune(),\n    trees = 100) |&gt;  \n  set_mode(\"classification\") |&gt;  \n  set_engine(\"ranger\", \n             # This is essential for vip()\n             importance = \"permutation\") \n\nweapon_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\nweapon_workflow &lt;- \n  workflow() |&gt; \n  add_recipe(weapon_recipe) |&gt;  \n  add_model(weapon_spec) \n\nweapon_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\ndoParallel::registerDoParallel()\n  \nset.seed(46257)\n  \nweapon_tune &lt;-\n  tune_grid(\n    weapon_workflow,\n    resamples = cv_weapon,\n# grid = 11 says to choose 11 parameter sets automatically \n    grid = 11)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nWarning: ! tune detected a parallel backend registered with foreach but no backend\n  registered with future.\nâ„¹ Support for parallel processing with foreach was soft-deprecated in tune\n  1.2.1.\nâ„¹ See ?parallelism (`?tune::parallelism()`) to learn more.\n\ndoParallel::stopImplicitCluster() \nweapon_tune\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 Ã— 4\n  splits               id    .metrics          .notes          \n  &lt;list&gt;               &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [11756/2940]&gt; Fold1 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n2 &lt;split [11757/2939]&gt; Fold2 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n3 &lt;split [11757/2939]&gt; Fold3 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n4 &lt;split [11757/2939]&gt; Fold4 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n5 &lt;split [11757/2939]&gt; Fold5 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n\n\n\ncollect_metrics(weapon_tune)\n\n# A tibble: 33 Ã— 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    17 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0417     5 0.00137 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.673      5 0.00677 Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0417     5 0.00137 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.673      5 0.00931 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0417     5 0.00128 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.672      5 0.00663 Preprocessor1_Model03\n10     3    21 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model04\n# â„¹ 23 more rows\n\n\n\nautoplot(weapon_tune) \n\n\n\n\n\nbest_weapon &lt;- select_best(weapon_tune, metric = \"roc_auc\")\nbest_weapon\n\n# A tibble: 1 Ã— 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    32 Preprocessor1_Model02\n\n\n\nweapon_final_wf &lt;- finalize_workflow(weapon_workflow, best_weapon)\nweapon_final_wf\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 32\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\nweapon_fit &lt;- fit(weapon_final_wf, weapon_train)\nweapon_fit\n\nâ•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L,      x), num.trees = ~100, min.node.size = min_rows(~32L, x),      importance = ~\"permutation\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  100 \nSample size:                      14696 \nNumber of independent variables:  10 \nMtry:                             1 \nTarget node size:                 32 \nVariable importance mode:         permutation \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.04166282 \n\n\n\nweapon_pred &lt;- \n  augment(weapon_fit, weapon_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0489   0.951\n 2 0                    0            0.0430   0.957\n 3 0                    0            0.0351   0.965\n 4 0                    0            0.0412   0.959\n 5 0                    0            0.0327   0.967\n 6 0                    0            0.0880   0.912\n 7 0                    0            0.0489   0.951\n 8 0                    0            0.0324   0.968\n 9 0                    0            0.0488   0.951\n10 0                    0            0.0324   0.968\n# â„¹ 14,686 more rows\n\n\n\nweapon_roc_plot &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_1, \n           event_level = \"second\") |&gt; \n  autoplot()\n\nweapon_roc_plot\n\nsaveRDS(weapon_roc_plot, here(\"models\", \"roc_graphs\", \"random_forest.rds\"))\n\n\nweapon_pred |&gt; \n  roc_auc(truth = WeaponCarryingSchool, \n           .pred_1, \n           event_level = \"second\")\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.683"
  },
  {
    "objectID": "models/random-forest.html",
    "href": "models/random-forest.html",
    "title": "Random Forest",
    "section": "",
    "text": "Library\n###Loading the data\n\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n\n###SPLIT THE DATA\n\nset.seed(2023)\n\nWeapon_split &lt;- initial_split(analysis_data, \n                               strata = WeaponCarryingSchool)\n\nweapon_train &lt;- training(Weapon_split)\nweapon_test &lt;- testing(Weapon_split)\n\nWeapon_split\n\n&lt;Training/Testing/Total&gt;\n&lt;14696/4899/19595&gt;\n\n\n###Lets check our work\n\nweapon_train |&gt; \n  tabyl(WeaponCarryingSchool)  |&gt; \n  adorn_pct_formatting(0) |&gt; \n  adorn_totals()\n\n WeaponCarryingSchool     n percent\n                    0 14042     96%\n                    1   654      4%\n                Total 14696       -\n\n\n\nweapon_test |&gt;  \n  tabyl(WeaponCarryingSchool)  |&gt; \n  adorn_pct_formatting(0) |&gt; \n  adorn_totals()\n\n WeaponCarryingSchool    n percent\n                    0 4705     96%\n                    1  194      4%\n                Total 4899       -\n\n\n\nset.seed(2023)\n\ncv_weapon &lt;- rsample::vfold_cv(weapon_train, \n                                v= 5,\n                                strata = WeaponCarryingSchool)\ncv_weapon\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 Ã— 2\n  splits               id   \n  &lt;list&gt;               &lt;chr&gt;\n1 &lt;split [11756/2940]&gt; Fold1\n2 &lt;split [11757/2939]&gt; Fold2\n3 &lt;split [11757/2939]&gt; Fold3\n4 &lt;split [11757/2939]&gt; Fold4\n5 &lt;split [11757/2939]&gt; Fold5\n\n\n\nweapon_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = weapon_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt; \n  step_dummy(all_nominal_predictors())\n\n\nweapon_spec &lt;- \n  rand_forest(\n    # the number of predictors to sample at each split\n    mtry = tune(), \n    # the number of observations needed to keep splitting nodes\n    min_n = tune(),\n    trees = 100) |&gt;  \n  set_mode(\"classification\") |&gt;  \n  set_engine(\"ranger\", \n             # This is essential for vip()\n             importance = \"permutation\") \n\nweapon_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\nweapon_workflow &lt;- \n  workflow() |&gt; \n  add_recipe(weapon_recipe) |&gt;  \n  add_model(weapon_spec) \n\nweapon_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\ndoParallel::registerDoParallel()\n  \nset.seed(46257)\n  \nweapon_tune &lt;-\n  tune_grid(\n    weapon_workflow,\n    resamples = cv_weapon,\n# grid = 11 says to choose 11 parameter sets automatically \n    grid = 11)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nWarning: ! tune detected a parallel backend registered with foreach but no backend\n  registered with future.\nâ„¹ Support for parallel processing with foreach was soft-deprecated in tune\n  1.2.1.\nâ„¹ See ?parallelism (`?tune::parallelism()`) to learn more.\n\ndoParallel::stopImplicitCluster() \nweapon_tune\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 Ã— 4\n  splits               id    .metrics          .notes          \n  &lt;list&gt;               &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [11756/2940]&gt; Fold1 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n2 &lt;split [11757/2939]&gt; Fold2 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n3 &lt;split [11757/2939]&gt; Fold3 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n4 &lt;split [11757/2939]&gt; Fold4 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n5 &lt;split [11757/2939]&gt; Fold5 &lt;tibble [33 Ã— 6]&gt; &lt;tibble [0 Ã— 3]&gt;\n\n\n\ncollect_metrics(weapon_tune)\n\n# A tibble: 33 Ã— 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    17 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0417     5 0.00137 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.673      5 0.00677 Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0417     5 0.00137 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.673      5 0.00931 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0417     5 0.00128 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.672      5 0.00663 Preprocessor1_Model03\n10     3    21 accuracy    binary     0.955      5 0.00160 Preprocessor1_Model04\n# â„¹ 23 more rows\n\n\n\nautoplot(weapon_tune) \n\n\n\n\n\nbest_weapon &lt;- select_best(weapon_tune, metric = \"roc_auc\")\nbest_weapon\n\n# A tibble: 1 Ã— 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    32 Preprocessor1_Model02\n\n\n\nweapon_final_wf &lt;- finalize_workflow(weapon_workflow, best_weapon)\nweapon_final_wf\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 32\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\nweapon_fit &lt;- fit(weapon_final_wf, weapon_train)\nweapon_fit\n\nâ•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L,      x), num.trees = ~100, min.node.size = min_rows(~32L, x),      importance = ~\"permutation\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  100 \nSample size:                      14696 \nNumber of independent variables:  10 \nMtry:                             1 \nTarget node size:                 32 \nVariable importance mode:         permutation \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.04166282 \n\n\n\nweapon_pred &lt;- \n  augment(weapon_fit, weapon_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0489   0.951\n 2 0                    0            0.0430   0.957\n 3 0                    0            0.0351   0.965\n 4 0                    0            0.0412   0.959\n 5 0                    0            0.0327   0.967\n 6 0                    0            0.0880   0.912\n 7 0                    0            0.0489   0.951\n 8 0                    0            0.0324   0.968\n 9 0                    0            0.0488   0.951\n10 0                    0            0.0324   0.968\n# â„¹ 14,686 more rows\n\n\n\nweapon_roc_plot &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_1, \n           event_level = \"second\") |&gt; \n  autoplot()\n\nweapon_roc_plot\n\nsaveRDS(weapon_roc_plot, here(\"models\", \"roc_graphs\", \"random_forest.rds\"))\n\n\nweapon_pred |&gt; \n  roc_auc(truth = WeaponCarryingSchool, \n           .pred_1, \n           event_level = \"second\")\n\n# A tibble: 1 Ã— 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.683"
  }
]